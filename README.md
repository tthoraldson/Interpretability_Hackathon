# Interpretibility Hackaton

This repository contains Jupyter notebooks that support our work for the [Alignment Jam's Interpretability Hackathon (2022)](https://forum.effectivealtruism.org/posts/vxLrFdrqRPdaHJwgs/join-the-interpretability-research-hackathon). These notebooks were run on Google Colab.

## File structure

```
Repository root
â”œâ”€â”€ notebooks
â”‚   â”œâ”€â”€ Decision_Transformer_Hackathon.ipynb: the notebook where our experiments have been carried out.
â”‚   â”œâ”€â”€ EasyTransformer_Demo.ipynb: an example notebook by Neel Nanda that demonstrates the usage of his EasyTransformer library.
â”‚   â””â”€â”€ No_Position_Experiment.ipynb: another example notebook by Neel Nanda that demonstrates a simple EasyTransformer interpretability experiment.
â””â”€â”€ README.md: this file.
```

## Executing our experiments

The notebooks were designed to run on [Google Colab](https://colab.research.google.com), so getting started should be easy.

1. On Colab, go to File â–¸ Open notebook, or press Ctrl/Cmd + O.

![First step](https://user-images.githubusercontent.com/7822554/201521709-d03a763e-6902-4cce-9fbe-2569f233fd99.png)

2. On the window that appears, go to the GitHub tab, and then select our experiments notebook at this repository.

![Second step](https://user-images.githubusercontent.com/7822554/201522012-9496627b-886e-456a-b359-a596f5635f5a.png)

3. Make sure that the Colab execution environment type has a GPU.

4. You're ready to run our notebook! ðŸŽ‰
